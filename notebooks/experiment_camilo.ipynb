{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbeab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc0c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from utils.dataloader import get_transforms, load_split_ids, build_caption_dataset\n",
    "from utils.caption_dataset import CaptionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92fd60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "with open(\"../data/processed/word2idx.json\", \"r\") as f:\n",
    "    word2idx = json.load(f)\n",
    "\n",
    "# Load image-caption sequences (already tokenized and cleaned)\n",
    "with open(\"../data/processed/image_caption_seqs.pkl\", \"rb\") as f:\n",
    "    image_caption_seqs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b33923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load official splits\n",
    "train_ids = load_split_ids(\"../data/Flickr8k_text/Flickr_8k.trainImages.txt\")\n",
    "val_ids   = load_split_ids(\"../data/Flickr8k_text/Flickr_8k.devImages.txt\")\n",
    "test_ids  = load_split_ids(\"../data/Flickr8k_text/Flickr_8k.testImages.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65931e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image folder path\n",
    "image_folder = \"../data/Flicker8k_Dataset\"\n",
    "\n",
    "# Define transforms\n",
    "transform_train = get_transforms(\"train\")\n",
    "transform_val   = get_transforms(\"val\")\n",
    "\n",
    "# Build datasets using shared util function\n",
    "train_dataset = build_caption_dataset(train_ids, image_caption_seqs, word2idx, image_folder, transform_train)\n",
    "val_dataset   = build_caption_dataset(val_ids, image_caption_seqs, word2idx, image_folder, transform_val)\n",
    "test_dataset  = build_caption_dataset(test_ids, image_caption_seqs, word2idx, image_folder, transform_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

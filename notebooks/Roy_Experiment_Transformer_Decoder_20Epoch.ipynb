{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQpALDCjNUeN",
        "outputId": "7643929d-1736-4dc0-f505-4931087c99b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "si6h8LTE0Fd-"
      },
      "outputs": [],
      "source": [
        "#!pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ6Tha3QtqAs",
        "outputId": "f1ef6c41-d519-4009-9a28-cd80af316997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: efficientnet_pytorch\n",
            "Version: 0.7.1\n",
            "Summary: EfficientNet implemented in PyTorch.\n",
            "Home-page: https://github.com/lukemelas/EfficientNet-PyTorch\n",
            "Author: Luke\n",
            "Author-email: lmelaskyriazi@college.harvard.edu\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: torch\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y7CSAQ36NfEP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z3v76yhrN9XD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KMuDRmF-zxEx"
      },
      "outputs": [],
      "source": [
        "# Enable full CUDA error reporting\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xOSHIVvTNilR"
      },
      "outputs": [],
      "source": [
        "# Change this to your actual Drive path\n",
        "base_path = \"/content/drive/MyDrive/UTS/SEM 4/DL/AT3/AT3-DL-image-captioning\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R_yHpHbwO7LS"
      },
      "outputs": [],
      "source": [
        "# Append utils path to Python path\n",
        "sys.path.append(os.path.join(base_path))\n",
        "\n",
        "# Set paths\n",
        "image_folder = os.path.join(base_path, \"data/Flicker8k_Dataset\")\n",
        "text_folder = os.path.join(base_path, \"data/Flickr8k_text\")\n",
        "processed_folder = os.path.join(base_path, \"data/processed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WQWZuy2jW71k"
      },
      "outputs": [],
      "source": [
        "from utils.dataloader import get_transforms, load_split_ids, build_caption_dataset\n",
        "from utils.caption_dataset import CaptionDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SqBe1u-xJ858"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vmwKUiAUQHeo"
      },
      "outputs": [],
      "source": [
        "# Load vocabulary\n",
        "with open(os.path.join(processed_folder, \"word2idx.json\"), \"r\") as f:\n",
        "    word2idx = json.load(f)\n",
        "\n",
        "with open(os.path.join(processed_folder, \"image_caption_seqs.pkl\"), \"rb\") as f:\n",
        "    image_caption_seqs = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PZYNg5MT4lRa"
      },
      "outputs": [],
      "source": [
        "# Fix invalid token indices\n",
        "vocab_size = len(word2idx)\n",
        "UNK_IDX = word2idx.get(\"<unk>\", word2idx[\"<pad>\"])\n",
        "for img_id, seqs in image_caption_seqs.items():\n",
        "    image_caption_seqs[img_id] = [\n",
        "        [w if w < vocab_size else UNK_IDX for w in seq] for seq in seqs\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5qpZG9KeQKgl"
      },
      "outputs": [],
      "source": [
        "# Load splits\n",
        "train_ids = load_split_ids(os.path.join(text_folder, \"Flickr_8k.trainImages.txt\"))\n",
        "val_ids   = load_split_ids(os.path.join(text_folder, \"Flickr_8k.devImages.txt\"))\n",
        "test_ids  = load_split_ids(os.path.join(text_folder, \"Flickr_8k.testImages.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "12EEX5HMQe87"
      },
      "outputs": [],
      "source": [
        "# Define transforms\n",
        "#transform_train = get_transforms(\"train\")\n",
        "#transform_val = get_transforms(\"val\")\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QLxKCuNGQjia"
      },
      "outputs": [],
      "source": [
        "# Build datasets\n",
        "train_dataset = build_caption_dataset(train_ids, image_caption_seqs, word2idx, image_folder, transform_train)\n",
        "val_dataset = build_caption_dataset(val_ids, image_caption_seqs, word2idx, image_folder, transform_val)\n",
        "test_dataset = build_caption_dataset(test_ids, image_caption_seqs, word2idx, image_folder, transform_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GxEl1hYKXW_k"
      },
      "outputs": [],
      "source": [
        "# === Positional Encoding ===\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aYwmged0gXDq"
      },
      "outputs": [],
      "source": [
        "# === Encoder: EfficientNet ===\n",
        "class EncoderEfficientNet(nn.Module):\n",
        "    def __init__(self, encoded_image_size=14, output_dim=256):\n",
        "        super().__init__()\n",
        "        self.backbone = EfficientNet.from_pretrained('efficientnet-b3')\n",
        "        self.pool = nn.AdaptiveAvgPool2d((encoded_image_size, encoded_image_size))\n",
        "        self.project = nn.Linear(1536, output_dim)  # Project to match decoder embed_dim\n",
        "\n",
        "    def forward(self, images):\n",
        "        features = self.backbone.extract_features(images)               # (B, 1536, H, W)\n",
        "        pooled = self.pool(features)                                    # (B, 1536, 14, 14)\n",
        "        flattened = pooled.flatten(2).permute(0, 2, 1)                  # (B, S, 1536)\n",
        "        projected = self.project(flattened)                             # (B, S, 256)\n",
        "        return projected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NLmNKL7Jgb-Q"
      },
      "outputs": [],
      "source": [
        "# === Decoder: Transformer ===\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=256, n_heads=4, num_layers=2, ff_dim=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.embedding.weight.requires_grad = False  # Freeze embedding layer\n",
        "        self.pos_encoder = PositionalEncoding(embed_dim)\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=embed_dim, nhead=n_heads,\n",
        "                                                   dim_feedforward=ff_dim, dropout=dropout)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, tgt_key_padding_mask=None):\n",
        "        tgt = self.embedding(tgt)\n",
        "        tgt = self.pos_encoder(tgt)\n",
        "        output = self.transformer_decoder(tgt.transpose(0, 1), memory.transpose(0, 1),\n",
        "                                          tgt_mask=tgt_mask,\n",
        "                                          tgt_key_padding_mask=tgt_key_padding_mask)\n",
        "        return self.fc(output.transpose(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qBx_DYuWgl4Y"
      },
      "outputs": [],
      "source": [
        "# === Full Model ===\n",
        "class TransformerCaptioningModel(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, images, captions):\n",
        "        memory = self.encoder(images)  # (B, S, D)\n",
        "        return self.decoder(captions, memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uSusZWhrxJLq"
      },
      "outputs": [],
      "source": [
        "from torch.cuda.amp import autocast, GradScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TAtynhvRsmXF"
      },
      "outputs": [],
      "source": [
        "# === Training Loop with AMP + Assertion ===\n",
        "def train_model(model, train_dataset, val_dataset, word2idx, device, batch_size=8, epochs=20, patience=3, lr=1e-4):\n",
        "    pad_idx = word2idx['<pad>']\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
        "\n",
        "    scaler = GradScaler()\n",
        "    #train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    #val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for images, captions, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
        "            images, captions = images.to(device), captions.to(device)\n",
        "\n",
        "            # === Assertion ===\n",
        "            assert captions[:, 1:].max().item() < len(word2idx), \"Target index exceeds vocab size\"\n",
        "            assert captions[:, 1:].min().item() >= 0, \"Negative target index detected\"\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with autocast():\n",
        "                outputs = model(images, captions[:, :-1])\n",
        "                loss = criterion(outputs.reshape(-1, outputs.size(-1)), captions[:, 1:].reshape(-1))\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        val_losses = []\n",
        "        references, hypotheses = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, captions, _ in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
        "                images, captions = images.to(device), captions.to(device)\n",
        "                with autocast():\n",
        "                    outputs = model(images, captions[:, :-1])\n",
        "                    loss = criterion(outputs.reshape(-1, outputs.size(-1)), captions[:, 1:].reshape(-1))\n",
        "                val_losses.append(loss.item())\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=2)\n",
        "                for ref, pred in zip(captions, preds):\n",
        "                    ref_tokens = [w for w in ref.tolist() if w not in {pad_idx, word2idx['<start>'], word2idx['<end>']}]\n",
        "                    pred_tokens = [w for w in pred.tolist() if w not in {pad_idx, word2idx['<start>'], word2idx['<end>']}]\n",
        "                    references.append([ref_tokens])\n",
        "                    hypotheses.append(pred_tokens)\n",
        "\n",
        "        avg_train_loss = np.mean(train_losses)\n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        bleu1 = corpus_bleu(references, hypotheses, weights=(1, 0, 0, 0))\n",
        "        bleu2 = corpus_bleu(references, hypotheses, weights=(0.5, 0.5, 0, 0))\n",
        "        bleu3 = corpus_bleu(references, hypotheses, weights=(0.33, 0.33, 0.33, 0))\n",
        "        bleu4 = corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
        "        print(f\"BLEU-1 = {bleu1:.4f}, BLEU-2 = {bleu2:.4f}, BLEU-3 = {bleu3:.4f}, BLEU-4 = {bleu4:.4f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), os.path.join(base_path, \"transformer_captioning_best.pt\"))\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzZABz59ZEDs",
        "outputId": "3c93fda5-85ef-45be-fdbd-f12d869cfe74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCnjMCOVYwso",
        "outputId": "b8102ae3-f02b-4f10-8ea2-36941db2d635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon May 19 14:02:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   61C    P8             18W /   72W |       3MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4cMzMToKuZX-"
      },
      "outputs": [],
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ-VjSL60hvJ",
        "outputId": "3e7d3497-26b0-4277-eec7-cd63351c4fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-11fd4d8d4ce2>:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 1 [Train]:   0%|          | 0/3750 [00:00<?, ?it/s]<ipython-input-21-11fd4d8d4ce2>:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1 [Train]: 100%|██████████| 3750/3750 [36:38<00:00,  1.71it/s]\n",
            "Epoch 1 [Val]:   0%|          | 0/625 [00:00<?, ?it/s]<ipython-input-21-11fd4d8d4ce2>:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1 [Val]: 100%|██████████| 625/625 [07:39<00:00,  1.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: Train Loss = 2.5361, Val Loss = 0.9982\n",
            "BLEU-1 = 0.7849, BLEU-2 = 0.7290, BLEU-3 = 0.6788, BLEU-4 = 0.6263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 [Train]: 100%|██████████| 3750/3750 [09:48<00:00,  6.37it/s]\n",
            "Epoch 2 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2: Train Loss = 0.6350, Val Loss = 0.3562\n",
            "BLEU-1 = 0.8595, BLEU-2 = 0.8348, BLEU-3 = 0.8121, BLEU-4 = 0.7860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3 [Train]: 100%|██████████| 3750/3750 [09:49<00:00,  6.36it/s]\n",
            "Epoch 3 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3: Train Loss = 0.2440, Val Loss = 0.1785\n",
            "BLEU-1 = 0.7375, BLEU-2 = 0.7195, BLEU-3 = 0.7035, BLEU-4 = 0.6818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4 [Train]: 100%|██████████| 3750/3750 [09:50<00:00,  6.35it/s]\n",
            "Epoch 4 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4: Train Loss = 0.1085, Val Loss = 0.1041\n",
            "BLEU-1 = 0.7666, BLEU-2 = 0.7526, BLEU-3 = 0.7404, BLEU-4 = 0.7227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5 [Train]: 100%|██████████| 3750/3750 [09:50<00:00,  6.35it/s]\n",
            "Epoch 5 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5: Train Loss = 0.0570, Val Loss = 0.0820\n",
            "BLEU-1 = 0.8127, BLEU-2 = 0.8008, BLEU-3 = 0.7903, BLEU-4 = 0.7752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6 [Train]: 100%|██████████| 3750/3750 [09:50<00:00,  6.35it/s]\n",
            "Epoch 6 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6: Train Loss = 0.0346, Val Loss = 0.0718\n",
            "BLEU-1 = 0.7172, BLEU-2 = 0.7038, BLEU-3 = 0.6922, BLEU-4 = 0.6743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7 [Train]: 100%|██████████| 3750/3750 [09:51<00:00,  6.34it/s]\n",
            "Epoch 7 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7: Train Loss = 0.0245, Val Loss = 0.0600\n",
            "BLEU-1 = 0.7299, BLEU-2 = 0.7174, BLEU-3 = 0.7066, BLEU-4 = 0.6897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8 [Train]: 100%|██████████| 3750/3750 [09:50<00:00,  6.35it/s]\n",
            "Epoch 8 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8: Train Loss = 0.0202, Val Loss = 0.0521\n",
            "BLEU-1 = 0.7159, BLEU-2 = 0.7032, BLEU-3 = 0.6923, BLEU-4 = 0.6751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9 [Train]: 100%|██████████| 3750/3750 [09:51<00:00,  6.34it/s]\n",
            "Epoch 9 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9: Train Loss = 0.0165, Val Loss = 0.0500\n",
            "BLEU-1 = 0.6853, BLEU-2 = 0.6725, BLEU-3 = 0.6617, BLEU-4 = 0.6441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10 [Train]: 100%|██████████| 3750/3750 [09:50<00:00,  6.35it/s]\n",
            "Epoch 10 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10: Train Loss = 0.0141, Val Loss = 0.0511\n",
            "BLEU-1 = 0.9462, BLEU-2 = 0.9408, BLEU-3 = 0.9359, BLEU-4 = 0.9294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11 [Train]: 100%|██████████| 3750/3750 [09:50<00:00,  6.35it/s]\n",
            "Epoch 11 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11: Train Loss = 0.0123, Val Loss = 0.0439\n",
            "BLEU-1 = 0.7058, BLEU-2 = 0.6935, BLEU-3 = 0.6830, BLEU-4 = 0.6661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12 [Train]: 100%|██████████| 3750/3750 [09:50<00:00,  6.35it/s]\n",
            "Epoch 12 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12: Train Loss = 0.0119, Val Loss = 0.0415\n",
            "BLEU-1 = 0.7313, BLEU-2 = 0.7196, BLEU-3 = 0.7096, BLEU-4 = 0.6935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13 [Train]: 100%|██████████| 3750/3750 [09:51<00:00,  6.35it/s]\n",
            "Epoch 13 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 13: Train Loss = 0.0109, Val Loss = 0.0409\n",
            "BLEU-1 = 0.8955, BLEU-2 = 0.8886, BLEU-3 = 0.8824, BLEU-4 = 0.8732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14 [Train]: 100%|██████████| 3750/3750 [09:52<00:00,  6.33it/s]\n",
            "Epoch 14 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 14: Train Loss = 0.0101, Val Loss = 0.0448\n",
            "BLEU-1 = 0.9574, BLEU-2 = 0.9530, BLEU-3 = 0.9490, BLEU-4 = 0.9436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15 [Train]: 100%|██████████| 3750/3750 [09:51<00:00,  6.34it/s]\n",
            "Epoch 15 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 15: Train Loss = 0.0098, Val Loss = 0.0405\n",
            "BLEU-1 = 0.9030, BLEU-2 = 0.8966, BLEU-3 = 0.8907, BLEU-4 = 0.8822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16 [Train]: 100%|██████████| 3750/3750 [09:51<00:00,  6.34it/s]\n",
            "Epoch 16 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 16: Train Loss = 0.0094, Val Loss = 0.0407\n",
            "BLEU-1 = 0.8052, BLEU-2 = 0.7954, BLEU-3 = 0.7867, BLEU-4 = 0.7732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17 [Train]: 100%|██████████| 3750/3750 [09:50<00:00,  6.35it/s]\n",
            "Epoch 17 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 17: Train Loss = 0.0084, Val Loss = 0.0355\n",
            "BLEU-1 = 0.7622, BLEU-2 = 0.7515, BLEU-3 = 0.7422, BLEU-4 = 0.7273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18 [Train]: 100%|██████████| 3750/3750 [09:52<00:00,  6.33it/s]\n",
            "Epoch 18 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 18: Train Loss = 0.0083, Val Loss = 0.0372\n",
            "BLEU-1 = 0.9093, BLEU-2 = 0.9032, BLEU-3 = 0.8978, BLEU-4 = 0.8898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19 [Train]: 100%|██████████| 3750/3750 [09:51<00:00,  6.34it/s]\n",
            "Epoch 19 [Val]: 100%|██████████| 625/625 [00:29<00:00, 20.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 19: Train Loss = 0.0080, Val Loss = 0.0460\n",
            "BLEU-1 = 0.8537, BLEU-2 = 0.8453, BLEU-3 = 0.8378, BLEU-4 = 0.8264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20 [Train]: 100%|██████████| 3750/3750 [09:50<00:00,  6.35it/s]\n",
            "Epoch 20 [Val]: 100%|██████████| 625/625 [00:29<00:00, 21.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 20: Train Loss = 0.0073, Val Loss = 0.0393\n",
            "BLEU-1 = 0.8539, BLEU-2 = 0.8457, BLEU-3 = 0.8384, BLEU-4 = 0.8273\n",
            "Early stopping at epoch 20\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "# === Run Training ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "encoder = EncoderEfficientNet()\n",
        "decoder = TransformerDecoder(vocab_size=vocab_size)\n",
        "model = TransformerCaptioningModel(encoder, decoder).to(device)\n",
        "\n",
        "trained_model = train_model(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset=val_dataset,\n",
        "    word2idx=word2idx,\n",
        "    device=device,\n",
        "    batch_size=8,\n",
        "    epochs=20,\n",
        "    patience=3,\n",
        "    lr=1e-4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "S0ObpFfY1Oz2"
      },
      "outputs": [],
      "source": [
        "save_path = \"/content/drive/MyDrive/UTS/SEM 4/DL/AT3/transformer_captioning_best.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CtzsIQti1Rcc"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
